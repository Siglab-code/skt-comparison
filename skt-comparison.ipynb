{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70ca67-000b-450d-bf5d-2a50fd0a95be",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap \n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import eccodes\n",
    "import cdsapi\n",
    "import cfgrib\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243dd548-d8ee-43d3-b845-fc6c04e50a4a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4085d2-acf3-4af6-9b0a-7eb06761ba75",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d24c8-f264-4d0c-b883-35bd76ae77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Function to extract temperature values from ERA5 dataset\n",
    "def extract_values(latitude, longitude, start_date, end_date, dataset_name, property_name):\n",
    "    dataset = ee.ImageCollection(dataset_name).select(property_name)\n",
    "    station_coordinates = ee.Geometry.Point([longitude, latitude])\n",
    "\n",
    "    # Split date range into smaller intervals\n",
    "    date_ranges = pd.date_range(start=start_date, end=end_date, freq='1YE')\n",
    "    \n",
    "    df_list = []\n",
    "    for i in range(len(date_ranges)-1):\n",
    "        filtered_dataset = dataset.filterDate(date_ranges[i].strftime('%Y-%m-%d'), date_ranges[i+1].strftime('%Y-%m-%d'))\n",
    "        \n",
    "        def extract_values(img):\n",
    "            mean_value = img.reduceRegion(\n",
    "                reducer=ee.Reducer.mean(),\n",
    "                geometry=station_coordinates,\n",
    "                scale=1,\n",
    "                maxPixels=1e9\n",
    "            ).get(property_name)\n",
    "    \n",
    "            return ee.Feature(None, {\n",
    "                'date': ee.Date(img.get('system:time_start')).format('YYYY-MM-dd'),\n",
    "                'value': mean_value\n",
    "            })\n",
    "    \n",
    "        values = filtered_dataset.map(extract_values)\n",
    "        value_list = values.getInfo()['features']\n",
    "        \n",
    "        df = pd.DataFrame([feature['properties'] for feature in value_list])\n",
    "        df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "        df.dropna(subset=['value'], inplace=True)\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    return pd.concat(df_list)\n",
    "\n",
    "# Function to extract temperature values from climate station data\n",
    "def extract_climate_station_values(climateID, start_date, end_date, layer_name, property_name):\n",
    "    url = f\"https://api.weather.gc.ca/collections/{layer_name}/items?datetime={start_date}/{end_date}&CLIMATE_IDENTIFIER={climateID}&f=json&sortby=LOCAL_DATE&limit=20000\"\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "    dates = []\n",
    "    y_axis = []\n",
    "\n",
    "    for feature in data['features']:\n",
    "        dates.append(pd.to_datetime(feature['properties']['LOCAL_DATE']))\n",
    "        y_axis.append(feature['properties'][property_name])\n",
    "\n",
    "    dates_to_remove = []\n",
    "    for date in pd.date_range(start=start_date, end=end_date, freq='D'):\n",
    "        if date not in dates:\n",
    "            dates.append(date)\n",
    "            y_axis.append(None)\n",
    "            dates_to_remove.append(date)    \n",
    "\n",
    "    dates, y_axis = zip(*sorted(zip(dates, y_axis)))\n",
    "    \n",
    "    return dates, y_axis\n",
    "\n",
    "def extraer_datos_nieve(latitud_objetivo, longitud_objetivo):\n",
    "  todos_los_datos = [] \n",
    "  ruta_archivos = \"D:\\\\Xavi\\\\Proyecto Canada\\\\snow_NSIDC\\\\snow_*.txt\"\n",
    "  chunksize = 100000\n",
    "\n",
    "  for archivo in glob.glob(ruta_archivos):\n",
    "    for chunk in pd.read_csv(archivo, sep=\"\\t\", header=None, chunksize=chunksize, skiprows=1):\n",
    "      # Asignar nombres de columna\n",
    "      chunk.columns = [\"fecha\", \"longitud\", \"latitud\", \"profundidad_nieve\"]\n",
    "\n",
    "      chunk[\"fecha\"] = chunk[\"fecha\"].astype(str)  # Convertir a string\n",
    "      chunk[\"fecha\"] = chunk[\"fecha\"].str[:-2]   # Eliminar los Ãºltimos dos ceros\n",
    "      chunk[\"fecha\"] = pd.to_datetime(chunk[\"fecha\"], format=\"%Y%m%d\") \n",
    "\n",
    "      # Calcular la distancia a las coordenadas objetivo\n",
    "      chunk[\"distancia\"] = ((chunk[\"latitud\"] - latitud_objetivo)**2 + \n",
    "                            (chunk[\"longitud\"] - longitud_objetivo)**2)**0.5\n",
    "\n",
    "      # Encontrar la fila con la menor distancia en el chunk\n",
    "      fila_cercana = chunk.loc[chunk[\"distancia\"].idxmin()]\n",
    "\n",
    "      # Agregar la fecha y profundidad de nieve a la lista\n",
    "      todos_los_datos.append([fila_cercana[\"fecha\"], fila_cercana[\"profundidad_nieve\"]])\n",
    "\n",
    "  # Crear un DataFrame con los datos recopilados\n",
    "  df_final = pd.DataFrame(todos_los_datos, columns=[\"fecha\", \"profundidad_nieve\"])\n",
    "  return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37f8b4-4abd-4917-9a02-e14815157575",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fccce-54f1-4255-9f5c-23523f6d4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R^2, MAE, and RMSE\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true= np.array(y_true)\n",
    "    y_pred = np.array(y_pred) \n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    bias = np.mean(np.array(y_true) - np.array(y_pred))\n",
    "    return r2, mae, rmse, bias\n",
    "\n",
    "def separate_data_by_year(dates, values):\n",
    "  year_data = {}\n",
    "  for date, value in zip(dates, values):\n",
    "    year = str(date.year)\n",
    "    if year not in year_data:\n",
    "      year_data[year] = []\n",
    "    year_data[year].append(value)  # Store only the value\n",
    "  return year_data\n",
    "\n",
    "def separate_data_by_month(dates, values):\n",
    "  month_data = {}\n",
    "  for date, value in zip(dates, values):\n",
    "    month = date.month\n",
    "    if month not in month_data:\n",
    "      month_data[month] = []\n",
    "    month_data[month].append(value) \n",
    "  return month_data\n",
    "\n",
    "def process_data_by_year(dates, values, additional_values=None):\n",
    "  year_data = separate_data_by_year(dates, values)\n",
    "  if additional_values:\n",
    "    for year, extra_vals in additional_values.items():\n",
    "      if year in year_data:\n",
    "        year_data[year].extend(extra_vals)  # Append if year exists\n",
    "      else:\n",
    "        year_data[year] = extra_vals.copy()  # Add year with values if it doesn't exist\n",
    "  return year_data\n",
    "\n",
    "def process_data_by_month(dates, values, additional_values=None):\n",
    "  month_data = separate_data_by_month(dates, values)\n",
    "  if additional_values:\n",
    "    for month, extra_vals in additional_values.items():\n",
    "      if month in month_data:\n",
    "        month_data[month].extend(extra_vals)  # Append additional values\n",
    "  return month_data\n",
    "\n",
    "def calculate_metrics_by_year(year_data, year_predictions):\n",
    "  metrics_by_year = {}\n",
    "  for year in year_data:\n",
    "    if year in year_predictions:\n",
    "      y_true_year = year_data[year]\n",
    "      y_pred_year = year_predictions[year]\n",
    "      metrics = calculate_metrics(y_true_year, y_pred_year)\n",
    "      metrics_by_year[year] = {\n",
    "          \"r2\": metrics[0],\n",
    "          \"mae\": metrics[1],\n",
    "          \"rmse\": metrics[2],\n",
    "          \"bias\": metrics[3]\n",
    "      }\n",
    "  return metrics_by_year\n",
    "\n",
    "def calculate_metrics_by_month(month_data, month_predictions):\n",
    "  metrics_by_month = {}\n",
    "  for month in month_data:\n",
    "    if month in month_predictions:\n",
    "      y_true_month = month_data[month]\n",
    "      y_pred_month = month_predictions[month]\n",
    "      metrics = calculate_metrics(y_true_month, y_pred_month)\n",
    "      metrics_by_month[month] = {\n",
    "          \"r2\": metrics[0],\n",
    "          \"mae\": metrics[1],\n",
    "          \"rmse\": metrics[2],\n",
    "          \"bias\": metrics[3]\n",
    "      }\n",
    "  return metrics_by_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d107f2f-4761-4568-88e0-187d13c42903",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268c120-594c-4a77-a3a4-822b38782d70",
   "metadata": {},
   "source": [
    "## Skin Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e1f5d-224e-4adc-bd2d-50c8ff487e09",
   "metadata": {},
   "source": [
    "### Metrics per location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e624746-658b-4df6-8c75-d8a3492d7fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Yukon Territory\n",
    "Parameter= 'Daily Skin Temperature'\n",
    "\n",
    "locations = [\n",
    "    {'name': \"YGS_WatsonLake_BH1\",'latitude': 60.151, 'longitude': -128.885, 'climateID': None}, \n",
    "    {'name': \"YGS_MarshLake_BH1\",'latitude': 60.561, 'longitude': -134.445, 'climateID': None},\n",
    "    {'name': \"YGS_Cowley_Creek_BH1\",'latitude': 60.593, 'longitude': -134.905, 'climateID': None},\n",
    "    {'name': \"YGS_Cowley_Creek_BH2\",'latitude': 60.593, 'longitude': -134.904, 'climateID': None},\n",
    "    {'name': \"YGS_FishLk_BH1\",'latitude': 60.653, 'longitude': -135.260, 'climateID': None},\n",
    "    {'name': \"YGS_Hamilton_Blvd_HB_BH1\",'latitude': 60.695, 'longitude': -135.096, 'climateID': None},\n",
    "    {'name': \"YGS_HJ_BH2\",'latitude': 60.772, 'longitude': -137.495, 'climateID': None},\n",
    "    {'name': \"YGS_HJ_BH5\",'latitude': 60.783, 'longitude': -137.531, 'climateID': None},\n",
    "    {'name': \"YGS_HJ_BH6\",'latitude': 60.786, 'longitude': -137.537, 'climateID': None},\n",
    "    {'name': \"YGS_HiddenValley\",'latitude': 60.830, 'longitude': -135.200, 'climateID': None},\n",
    "    {'name': \"YGS_TakhiniValley\",'latitude': 60.843, 'longitude': -135.673, 'climateID': None},\n",
    "    {'name': \"YGS_Takhini_Thawslump\",'latitude': 60.856, 'longitude': -135.515, 'climateID': None},\n",
    "    {'name': \"YGS_Nordenskiold_BH2\",'latitude': 61.856, 'longitude': -136.109, 'climateID': None},\n",
    "    {'name': \"YGS_Nordenskiold_BH3\",'latitude': 61.857, 'longitude': -136.109, 'climateID': None},\n",
    "    {'name': \"YGS_CanolRd\",'latitude': 61.924, 'longitude': -132.571, 'climateID': None},\n",
    "    {'name': \"YGS_Carmacks_BH3\",'latitude': 62.091, 'longitude': -136.299, 'climateID': None},\n",
    "    {'name': \"YGS_Faro\",'latitude': 62.223, 'longitude': -133.342, 'climateID': None},\n",
    "    {'name': \"HPW_Shakwak_1_toe\",'latitude': 62.336 , 'longitude': -140.834, 'climateID': None},\n",
    "    {'name': \"YGS_BeaverCreek\",'latitude': 62.337, 'longitude': -140.835, 'climateID': None},\n",
    "    {'name': \"HPW_Shakwak_orig_berm\",'latitude': 62.338, 'longitude': -104.835, 'climateID': None},\n",
    "    {'name': \"HPW_Shakwak_orig_centre\",'latitude': 62.338, 'longitude': -140.834, 'climateID': None},\n",
    "    {'name': \"YGS_BeaverCreek_BH1\",'latitude': 62.371, 'longitude': -140.876, 'climateID': None},\n",
    "    {'name': \"YGS_BeaverCreek_BH3\",'latitude': 62.384, 'longitude': -140.870, 'climateID': None},\n",
    "    {'name': \"YGS_BeaverCreek_BH2\",'latitude': 62.400, 'longitude': -140.866, 'climateID': None},\n",
    "    {'name': \"Coffee_KPBH4\",'latitude': 62.858, 'longitude': -139.406, 'climateID': None},\n",
    "    {'name': \"Coffee_KPBH1\",'latitude': 62.863, 'longitude': -139.399, 'climateID': None},\n",
    "    {'name': \"HPW_StewartCrossing\",'latitude': 63.374, 'longitude': -136.677, 'climateID': None}, \n",
    "    {'name': \"YGS_DawsonDump\",'latitude': 64.031, 'longitude': -139.294, 'climateID': None},\n",
    "    {'name': \"YGS_DawsonSchool\",'latitude': 64.061, 'longitude': -139.430, 'climateID': None},\n",
    "    {'name': \"AAM_ClintonCk_BH18-08\",'latitude': 64.452, 'longitude': -140.728, 'climateID': None},\n",
    "    {'name': \"AAM_ClintonCk_BH18-15\",'latitude': 64.456, 'longitude': -140.715, 'climateID': None},\n",
    "    {'name': \"YGS_USArray_I30M_MtDempster\",'latitude': 65.222, 'longitude': -136.376, 'climateID': None},\n",
    "    {'name': \"YGS_Dempster_KM190\",'latitude': 65.326, 'longitude': -138.240, 'climateID': None},\n",
    "    {'name': \"YGS_Ogilvie_BH1\",'latitude': 65.664, 'longitude': -138.134, 'climateID': None},\n",
    "    {'name': \"YGS_USArray_H31M_PeelRiver\",'latitude': 65.805, 'longitude': -134.342, 'climateID': None},\n",
    "    {'name': \"YGS_USArray_H29_Whitestone\",'latitude': 66.219, 'longitude': -138.368, 'climateID': None},    \n",
    "    {'name': \"YGS_EagleRiver\",'latitude': 66.444, 'longitude': -136.708, 'climateID': None},\n",
    "    {'name': \"YGS_Dempster_KM934-2\",'latitude': 66.519, 'longitude': -136.512, 'climateID': None},\n",
    "    {'name': \"YGS_Dempster_KM934-1\",'latitude': 66.520, 'longitude': -136.512, 'climateID': None},\n",
    "    {'name': \"YGS_USArray_G29M_PineCk\",'latitude': 66.911, 'longitude': -138.022, 'climateID': None},\n",
    "    {'name': \"YGS_USArray_E29M_BlowRiver\",'latitude': 68.388, 'longitude': -137.896, 'climateID': None}\n",
    "]\n",
    "\n",
    "L=[]\n",
    "R2_ERA5=[]\n",
    "MAE_ERA5=[]\n",
    "RMSE_ERA5=[]\n",
    "BIAS_ERA5=[]\n",
    "R2_ERA5_LAND=[]\n",
    "MAE_ERA5_LAND=[]\n",
    "RMSE_ERA5_LAND=[]\n",
    "BIAS_ERA5_LAND=[]\n",
    "R2_THERMAL=[]\n",
    "MAE_THERMAL=[]\n",
    "RMSE_THERMAL=[]\n",
    "BIAS_THERMAL=[]\n",
    "R2_MODIS=[]\n",
    "MAE_MODIS=[]\n",
    "RMSE_MODIS=[]\n",
    "BIAS_MODIS=[]\n",
    "\n",
    "# Loop over each location and plot temperature data\n",
    "for location in locations:\n",
    "    #ERA5-LAND - 11.1 km\n",
    "    df_era5_land = extract_values(location['latitude'], location['longitude'], '1950-01-02', '2024-01-31','ECMWF/ERA5_LAND/DAILY_AGGR', 'skin_temperature')\n",
    "    df_era5_land_dates=pd.to_datetime(df_era5_land['date'])\n",
    "    df_era5_land_value=df_era5_land['value']-273.15\n",
    "    df_era5_land_dates, df_era5_land_value = zip(*sorted(zip(df_era5_land_dates, df_era5_land_value)))\n",
    "    #ERA5 - 27.8 km\n",
    "    years = list(range(2000, 2025))\n",
    "    skin_temperature_by_year = []\n",
    "    for year in years:\n",
    "        ds_year = xr.open_dataset(f'era5_skt{year}.grib', engine='cfgrib')\n",
    "        ds_year_by_day = ds_year['skt'].resample(time='D').mean()\n",
    "        skin_temperature_by_year.append(ds_year_by_day)\n",
    "        ds_year.close()\n",
    "    skin_temperature_combined = xr.concat(skin_temperature_by_year, dim='time')\n",
    "    skin_temperature = skin_temperature_combined.sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest') - 273.15\n",
    "    df_era5_dates= pd.to_datetime(skin_temperature.time)\n",
    "    df_era5_value=skin_temperature.values\n",
    "    df_era5_dates, df_era5_value = zip(*sorted(zip(df_era5_dates, df_era5_value)))\n",
    "    #INFO THERMAL - 1 km\n",
    "    df_thermal = extract_values(location['latitude'], location['longitude'], '2012-01-19', '2024-03-01','NOAA/VIIRS/001/VNP21A1D','LST_1KM')\n",
    "    df_thermal_dates=pd.to_datetime(df_thermal['date'])\n",
    "    df_thermal_value=df_thermal['value']-273.15\n",
    "    df_thermal_dates, df_thermal_value = zip(*sorted(zip(df_thermal_dates, df_thermal_value)))\n",
    "    #INFO MODIS - 1 km\n",
    "    df_modis=extract_values(location['latitude'], location['longitude'], '2000-02-24', '2024-03-24','MODIS/061/MOD11A1','LST_Day_1km')\n",
    "    df_modis_dates=pd.to_datetime(df_modis['date'])\n",
    "    df_modis_value=(df_modis['value']*0.02)-273.15\n",
    "    df_modis_dates, df_modis_value = zip(*sorted(zip(df_modis_dates, df_modis_value)))\n",
    "    #CLIMATE STATIONS\n",
    "    # Ruta al archivo CSV\n",
    "    file_path = f\"{location['name']}.csv\"\n",
    "    data = pd.read_csv(file_path, sep=\",\")\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    station_dates=data[\"Date\"]\n",
    "    station_value=data[\"0__m\"]\n",
    "    station_dates,station_value = zip(*sorted(zip(station_dates,station_value)))\n",
    "    mask = np.isnan(station_value)\n",
    "    non_nan_indices = np.logical_not(mask)\n",
    "    # Utiliza los Ã­ndices no NaN para obtener los valores y fechas correspondientes\n",
    "    station_value = np.array(station_value)[non_nan_indices]\n",
    "    station_dates = np.array(station_dates)[non_nan_indices]\n",
    "\n",
    "\n",
    "    if len(station_dates) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #Remove dates not present in both datasets. Siempre la estacion va a tener menos data.\n",
    "        common_dates_era5 = set(df_era5_dates).intersection(set(station_dates)) #se extraen las fechas que tienen iguales\n",
    "        common_dates_era5_land=set(df_era5_land_dates).intersection(set(station_dates))\n",
    "        common_dates_thermal=set(df_thermal_dates).intersection(set(station_dates))\n",
    "        common_dates_modis=set(df_modis_dates).intersection(set(station_dates))\n",
    "        \n",
    "        #VALORES ERA5\n",
    "        era5_dates=[]\n",
    "        era5_value=[]\n",
    "        for a,b in zip(df_era5_dates,df_era5_value):\n",
    "            if a in common_dates_era5:\n",
    "                era5_dates.append(a)\n",
    "                era5_value.append(b)\n",
    "        st_dates_era5=[]\n",
    "        st_value_era5=[]\n",
    "        for a,b in zip(station_dates,station_value):\n",
    "            if a in common_dates_era5:\n",
    "                st_dates_era5.append(a)\n",
    "                st_value_era5.append(b)\n",
    "    \n",
    "        #VALORES ERA5-LAND\n",
    "        era5_land_dates=[]\n",
    "        era5_land_value=[]\n",
    "        for a,b in zip(df_era5_land_dates,df_era5_land_value):\n",
    "            if a in common_dates_era5_land:\n",
    "                era5_land_dates.append(a)\n",
    "                era5_land_value.append(b)\n",
    "        st_dates_era5_land=[]\n",
    "        st_value_era5_land=[]\n",
    "        for a,b in zip(station_dates,station_value):\n",
    "            if a in common_dates_era5_land:\n",
    "                st_dates_era5_land.append(a)\n",
    "                st_value_era5_land.append(b)\n",
    "            \n",
    "        #VALORES THERMAL IMAGES\n",
    "        thermal_dates=[]\n",
    "        thermal_value=[]\n",
    "        for a,b in zip(df_thermal_dates,df_thermal_value):\n",
    "            if a in common_dates_thermal:\n",
    "                thermal_dates.append(a)\n",
    "                thermal_value.append(b)\n",
    "        st_dates_thermal=[]\n",
    "        st_value_thermal=[]\n",
    "        for a,b in zip(station_dates,station_value):\n",
    "            if a in common_dates_thermal:\n",
    "                st_dates_thermal.append(a)\n",
    "                st_value_thermal.append(b)\n",
    "\n",
    "        #VALORES MODIS\n",
    "        modis_dates=[]\n",
    "        modis_value=[]\n",
    "        for a,b in zip(df_modis_dates,df_modis_value):\n",
    "            if a in common_dates_modis:\n",
    "                modis_dates.append(a)\n",
    "                modis_value.append(b)\n",
    "        st_dates_modis=[]\n",
    "        st_value_modis=[]\n",
    "        for a,b in zip(station_dates,station_value):\n",
    "            if a in common_dates_modis:\n",
    "                st_dates_modis.append(a)\n",
    "                st_value_modis.append(b)\n",
    "                \n",
    "        # Calculate metrics\n",
    "        r2_era5, mae_era5, rmse_era5, bias_era5 = calculate_metrics(st_value_era5, era5_value)\n",
    "        r2_era5_land, mae_era5_land, rmse_era5_land, bias_era5_land = calculate_metrics(st_value_era5_land, era5_land_value)\n",
    "        r2_thermal, mae_thermal, rmse_thermal, bias_thermal=calculate_metrics(st_value_thermal, thermal_value)\n",
    "        r2_modis, mae_modis, rmse_modis, bias_modis=calculate_metrics(st_value_modis, modis_value)\n",
    "        #if r2_era5<0:\n",
    "         #   r2_era5=np.nan\n",
    "        #if r2_era5_land<0:\n",
    "        #    r2_era5_land=np.nan\n",
    "        print(f\"Metrics ERA5 for {location['name']} - R^2: {r2_era5:.2f}, MAE: {mae_era5:.2f}, RMSE: {rmse_era5:.2f}, Bias: {bias_era5:.2f}\")\n",
    "        print(f\"Metrics ERA5-LAND for {location['name']} - R^2: {r2_era5_land:.2f}, MAE: {mae_era5_land:.2f}, RMSE: {rmse_era5_land:.2f}, Bias: {bias_era5_land:.2f}\")\n",
    "        print(f\"Metrics VNP21A1D for {location['name']} - R^2: {r2_thermal:.2f}, MAE: {mae_thermal:.2f}, RMSE: {rmse_thermal:.2f}, Bias: {bias_thermal:.2f}\")\n",
    "        print(f\"Metrics MODIS for {location['name']} - R^2: {r2_modis:.2f}, MAE: {mae_modis:.2f}, RMSE: {rmse_modis:.2f}, Bias: {bias_modis:.2f}\")\n",
    "        L.append(location['name'])\n",
    "        R2_ERA5.append(r2_era5)\n",
    "        MAE_ERA5.append(mae_era5)\n",
    "        RMSE_ERA5.append(rmse_era5)\n",
    "        BIAS_ERA5.append(bias_era5)\n",
    "        R2_ERA5_LAND.append(r2_era5_land)\n",
    "        MAE_ERA5_LAND.append(mae_era5_land)\n",
    "        RMSE_ERA5_LAND.append(rmse_era5_land)\n",
    "        BIAS_ERA5_LAND.append(bias_era5_land)\n",
    "        R2_THERMAL.append(r2_thermal)\n",
    "        MAE_THERMAL.append(mae_thermal)\n",
    "        RMSE_THERMAL.append(rmse_thermal)\n",
    "        BIAS_THERMAL.append(bias_thermal)\n",
    "        R2_MODIS.append(r2_modis)\n",
    "        MAE_MODIS.append(mae_modis)\n",
    "        RMSE_MODIS.append(rmse_modis)\n",
    "        BIAS_MODIS.append(bias_modis)\n",
    "\n",
    "# Set the positions of the points on the x-axis\n",
    "x = np.arange(len(L))\n",
    "\n",
    "# Define the metrics and corresponding data lists\n",
    "metrics = ['R2', 'MAE', 'RMSE', 'BIAS']\n",
    "data_ERA5 = [R2_ERA5, MAE_ERA5, RMSE_ERA5, BIAS_ERA5]\n",
    "data_ERA5_LAND = [R2_ERA5_LAND, MAE_ERA5_LAND, RMSE_ERA5_LAND, BIAS_ERA5_LAND]\n",
    "data_THERMAL=[R2_THERMAL, MAE_THERMAL, RMSE_THERMAL, BIAS_THERMAL]\n",
    "data_MODIS=[R2_MODIS, MAE_MODIS, RMSE_MODIS, BIAS_MODIS]\n",
    "\n",
    "# Iterate over metrics and create plots\n",
    "for metric, data_era5, data_era5_land, data_thermal, data_modis in zip(metrics, data_ERA5, data_ERA5_LAND,data_THERMAL, data_MODIS):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.scatter(x, data_era5, label='ERA5')\n",
    "    for i, location in enumerate(L):\n",
    "        plt.plot([i, i], [0, data_era5[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x, data_era5_land, label='ERA5-LAND')\n",
    "    for i, location in enumerate(L):\n",
    "        plt.plot([i, i], [0, data_era5_land[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x,data_thermal, label='VNP21A1D')\n",
    "    for i,location in enumerate(L):\n",
    "        plt.plot([i,i],[0,data_thermal[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x,data_modis, label='MODIS')\n",
    "    for i,location in enumerate(L):\n",
    "        plt.plot([i,i],[0,data_modis[i]], color='black', linestyle='-')\n",
    "    plt.xlabel('Climate Stations')\n",
    "    plt.ylabel(metric)\n",
    "    if metric == 'R2':\n",
    "        plt.ylim(min(min(data_era5_land), min(data_era5),min(data_thermal),min(data_modis)) - 0.01, max(max(data_era5_land), max(data_era5),max(data_thermal),max(data_modis)) + 0.01)\n",
    "    else:\n",
    "        plt.ylim(min(min(data_era5_land), min(data_era5),min(data_thermal),min(data_modis)) - 0.1, max(max(data_era5_land), max(data_era5),max(data_thermal),max(data_modis)) + 0.1)\n",
    "    plt.axhline(y=0, color='black', linestyle='-')\n",
    "    plt.title(metric + ' ' + Parameter)\n",
    "    plt.xticks(x, L, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28b0f7-d390-4c03-a052-7fe12bb2e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manitoba territory\n",
    "Parameter= 'Daily Skin Temperature'\n",
    "\n",
    "locations = [\n",
    "    {'name': \"alonsa\",'latitude':50.70 , 'longitude': -99.07, 'climateID': None}, \n",
    "    {'name': \"altona\",'latitude':49.10 , 'longitude': -97.53, 'climateID': None},\n",
    "    {'name': \"arborg\",'latitude':50.90 , 'longitude': -97.27, 'climateID': None},\n",
    "    {'name': \"argue\",'latitude':49.44 , 'longitude': -100.31, 'climateID': None},\n",
    "    {'name': \"baldur\",'latitude':49.36, 'longitude': -99.25, 'climateID': None},\n",
    "    {'name': \"boissevain\",'latitude': 49.24, 'longitude': -100.06, 'climateID': None},\n",
    "    {'name': \"carman\",'latitude':49.50 , 'longitude': -98.03, 'climateID': None},\n",
    "    {'name': \"cartwright\",'latitude':49.09 , 'longitude': -99.32, 'climateID': None},\n",
    "    {'name': \"deloraine\",'latitude': 49.15, 'longitude': -100.49, 'climateID': None},\n",
    "    {'name': \"elmcreek\",'latitude': 49.68, 'longitude': -97.98, 'climateID': None},\n",
    "    {'name': \"ethelbert\",'latitude':  51.57, 'longitude': -100.49, 'climateID': None},\n",
    "    {'name': \"findlay\",'latitude': 49.55, 'longitude': -100.78, 'climateID': None},\n",
    "    {'name': \"fisherton\",'latitude': 51.18, 'longitude': -97.77, 'climateID': None},\n",
    "    {'name': \"Forkriver\",'latitude':51.54 , 'longitude': -100.01, 'climateID': None},\n",
    "    {'name': \"forrest\",'latitude': 50.05, 'longitude': -99.93, 'climateID': None},\n",
    "    {'name': \"gladstone\",'latitude': 50.14, 'longitude': -98.95, 'climateID': None},\n",
    "    {'name': \"glenboro\",'latitude': 49.55, 'longitude': -99.33, 'climateID': None},\n",
    "    {'name': \"inwood\",'latitude':50.51 , 'longitude': -97.62, 'climateID': None}, \n",
    "    {'name': \"manitou\",'latitude':49.25 , 'longitude':-98.55, 'climateID': None},\n",
    "    {'name': \"menisino\",'latitude':49.10 , 'longitude': -96.14, 'climateID': None},\n",
    "    {'name': \"minitonas\",'latitude': 52.14, 'longitude': -100.88, 'climateID': None},\n",
    "    {'name': \"minto\",'latitude': 49.43, 'longitude':-99.92, 'climateID': None},\n",
    "    {'name': \"Mountainside\",'latitude': 49.13, 'longitude':-100.30 , 'climateID': None},\n",
    "    {'name': \"Snowflake\",'latitude':49.02 , 'longitude':-98.67 , 'climateID': None},\n",
    "    {'name': \"somerset\",'latitude':49.41 , 'longitude': -98.70, 'climateID': None},\n",
    "    {'name': \"souris\",'latitude': 49.63, 'longitude': -100.20, 'climateID': None},\n",
    "    {'name': \"starbuck\",'latitude':49.77 , 'longitude':-97.66 , 'climateID': None},\n",
    "    {'name': \"steinbach\",'latitude': 49.55, 'longitude':-96.68 , 'climateID': None},\n",
    "    {'name': \"swanvalley\",'latitude':52.06 , 'longitude': -101.49, 'climateID': None},\n",
    "    {'name': \"Taylorspoint\",'latitude':50.86 , 'longitude':-98.45 , 'climateID': None},\n",
    "    {'name': \"teulon\",'latitude':50.38 , 'longitude': -97.24, 'climateID': None},\n",
    "    {'name': \"treherne\",'latitude':49.63 , 'longitude': -98.68, 'climateID': None},\n",
    "    {'name': \"waskada\",'latitude':49.09 , 'longitude':-100.93 , 'climateID': None},\n",
    "    {'name': \"wawanesa\",'latitude':49.64 , 'longitude': -99.66, 'climateID': None},\n",
    "    {'name': \"windygates\",'latitude':49.01 , 'longitude':-98.38 , 'climateID': None},\n",
    "]\n",
    "\n",
    "L=[]\n",
    "R2_ERA5=[]\n",
    "MAE_ERA5=[]\n",
    "RMSE_ERA5=[]\n",
    "BIAS_ERA5=[]\n",
    "R2_ERA5_LAND=[]\n",
    "MAE_ERA5_LAND=[]\n",
    "RMSE_ERA5_LAND=[]\n",
    "BIAS_ERA5_LAND=[]\n",
    "R2_THERMAL=[]\n",
    "MAE_THERMAL=[]\n",
    "RMSE_THERMAL=[]\n",
    "BIAS_THERMAL=[]\n",
    "R2_MODIS=[]\n",
    "MAE_MODIS=[]\n",
    "RMSE_MODIS=[]\n",
    "BIAS_MODIS=[]\n",
    "\n",
    "# Loop over each location and plot temperature data\n",
    "for location in locations:\n",
    "    try:\n",
    "    #ERA5-LAND - 11.1 km\n",
    "        df_era5_land = extract_values(location['latitude'], location['longitude'], '1950-01-02', '2024-01-31','ECMWF/ERA5_LAND/DAILY_AGGR', 'skin_temperature')\n",
    "        df_era5_land_dates=pd.to_datetime(df_era5_land['date'])\n",
    "        df_era5_land_value=df_era5_land['value']-273.15\n",
    "        df_era5_land_dates, df_era5_land_value = zip(*sorted(zip(df_era5_land_dates, df_era5_land_value)))\n",
    "        #ERA5 - 27.8 km\n",
    "        years = list(range(2000, 2025))\n",
    "        skin_temperature_by_year = []\n",
    "        for year in years:\n",
    "            ds_year = xr.open_dataset(f'era5_skt{year}.grib', engine='cfgrib')\n",
    "            ds_year_by_day = ds_year['skt'].resample(time='D').mean()\n",
    "            skin_temperature_by_year.append(ds_year_by_day)\n",
    "            ds_year.close()\n",
    "        skin_temperature_combined = xr.concat(skin_temperature_by_year, dim='time')\n",
    "        skin_temperature = skin_temperature_combined.sel(latitude=location['latitude'], longitude=location['longitude'], method='nearest') - 273.15\n",
    "        df_era5_dates= pd.to_datetime(skin_temperature.time)\n",
    "        df_era5_value=skin_temperature.values\n",
    "        df_era5_dates, df_era5_value = zip(*sorted(zip(df_era5_dates, df_era5_value)))\n",
    "        #INFO THERMAL - 1 km\n",
    "        df_thermal = extract_values(location['latitude'], location['longitude'], '2012-01-19', '2024-03-01','NOAA/VIIRS/001/VNP21A1D','LST_1KM')\n",
    "        df_thermal_dates=pd.to_datetime(df_thermal['date'])\n",
    "        df_thermal_value=df_thermal['value']-273.15\n",
    "        df_thermal_dates, df_thermal_value = zip(*sorted(zip(df_thermal_dates, df_thermal_value)))\n",
    "        #INFO MODIS - 1 km\n",
    "        df_modis=extract_values(location['latitude'], location['longitude'], '2000-02-24', '2024-03-24','MODIS/061/MOD11A1','LST_Day_1km')\n",
    "        df_modis_dates=pd.to_datetime(df_modis['date'])\n",
    "        df_modis_value=(df_modis['value']*0.02)-273.15\n",
    "        df_modis_dates, df_modis_value = zip(*sorted(zip(df_modis_dates, df_modis_value)))\n",
    "        #CLIMATE STATIONS\n",
    "        file_path = f\"{location['name']}_data.txt\"    \n",
    "        data = pd.read_csv(file_path, sep=\",\")\n",
    "        data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "        station_dates = data[\"date\"]\n",
    "        station_value = data[\"avg_soil_t05\"]\n",
    "        station_dates, station_value = zip(*sorted(zip(station_dates, station_value)))\n",
    "        mask = np.isnan(station_value)\n",
    "        non_nan_indices = np.logical_not(mask)\n",
    "        station_value = np.array(station_value)[non_nan_indices]\n",
    "        station_dates = np.array(station_dates)[non_nan_indices]\n",
    "        # Crear un DataFrame con las fechas y los valores filtrados\n",
    "        filtered_data = pd.DataFrame({\"date\": station_dates, \"avg_soil_t05\": station_value})\n",
    "        grouped_data = filtered_data.groupby(\"date\")[\"avg_soil_t05\"].mean().reset_index()\n",
    "        station_dates = grouped_data[\"date\"].to_numpy()\n",
    "        station_dates = pd.to_datetime(station_dates)\n",
    "        station_value = grouped_data[\"avg_soil_t05\"].to_numpy()\n",
    "    \n",
    "        if len(station_dates) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #Remove dates not present in both datasets. Siempre la estacion va a tener menos data.\n",
    "            common_dates_era5 = set(df_era5_dates).intersection(set(station_dates)) #se extraen las fechas que tienen iguales\n",
    "            common_dates_era5_land=set(df_era5_land_dates).intersection(set(station_dates))\n",
    "            common_dates_thermal=set(df_thermal_dates).intersection(set(station_dates))\n",
    "            common_dates_modis=set(df_modis_dates).intersection(set(station_dates))\n",
    "            \n",
    "            #VALORES ERA5\n",
    "            era5_dates=[]\n",
    "            era5_value=[]\n",
    "            for a,b in zip(df_era5_dates,df_era5_value):\n",
    "                if a in common_dates_era5:\n",
    "                    era5_dates.append(a)\n",
    "                    era5_value.append(b)\n",
    "            st_dates_era5=[]\n",
    "            st_value_era5=[]\n",
    "            for a,b in zip(station_dates,station_value):\n",
    "                if a in common_dates_era5:\n",
    "                    st_dates_era5.append(a)\n",
    "                    st_value_era5.append(b)\n",
    "        \n",
    "            #VALORES ERA5-LAND\n",
    "            era5_land_dates=[]\n",
    "            era5_land_value=[]\n",
    "            for a,b in zip(df_era5_land_dates,df_era5_land_value):\n",
    "                if a in common_dates_era5_land:\n",
    "                    era5_land_dates.append(a)\n",
    "                    era5_land_value.append(b)\n",
    "            st_dates_era5_land=[]\n",
    "            st_value_era5_land=[]\n",
    "            for a,b in zip(station_dates,station_value):\n",
    "                if a in common_dates_era5_land:\n",
    "                    st_dates_era5_land.append(a)\n",
    "                    st_value_era5_land.append(b)\n",
    "               \n",
    "            #VALORES THERMAL IMAGES\n",
    "            thermal_dates=[]\n",
    "            thermal_value=[]\n",
    "            for a,b in zip(df_thermal_dates,df_thermal_value):\n",
    "                if a in common_dates_thermal:\n",
    "                    thermal_dates.append(a)\n",
    "                    thermal_value.append(b)\n",
    "            st_dates_thermal=[]\n",
    "            st_value_thermal=[]\n",
    "            for a,b in zip(station_dates,station_value):\n",
    "                if a in common_dates_thermal:\n",
    "                    st_dates_thermal.append(a)\n",
    "                    st_value_thermal.append(b)\n",
    "    \n",
    "            #VALORES MODIS\n",
    "            modis_dates=[]\n",
    "            modis_value=[]\n",
    "            for a,b in zip(df_modis_dates,df_modis_value):\n",
    "                if a in common_dates_modis:\n",
    "                    modis_dates.append(a)\n",
    "                    modis_value.append(b)\n",
    "            st_dates_modis=[]\n",
    "            st_value_modis=[]\n",
    "            for a,b in zip(station_dates,station_value):\n",
    "                if a in common_dates_modis:\n",
    "                    st_dates_modis.append(a)\n",
    "                    st_value_modis.append(b)\n",
    "                    \n",
    "            # Calculate metrics\n",
    "            r2_era5, mae_era5, rmse_era5, bias_era5 = calculate_metrics(st_value_era5, era5_value)\n",
    "            r2_era5_land, mae_era5_land, rmse_era5_land, bias_era5_land = calculate_metrics(st_value_era5_land, era5_land_value)\n",
    "            r2_thermal, mae_thermal, rmse_thermal, bias_thermal=calculate_metrics(st_value_thermal, thermal_value)\n",
    "            r2_modis, mae_modis, rmse_modis, bias_modis=calculate_metrics(st_value_modis, modis_value)\n",
    "            #if r2_era5<0:\n",
    "             #   r2_era5=np.nan\n",
    "            #if r2_era5_land<0:\n",
    "            #    r2_era5_land=np.nan\n",
    "            print(f\"Metrics ERA5 for {location['name']} - R^2: {r2_era5:.2f}, MAE: {mae_era5:.2f}, RMSE: {rmse_era5:.2f}, Bias: {bias_era5:.2f}\")\n",
    "            print(f\"Metrics ERA5-LAND for {location['name']} - R^2: {r2_era5_land:.2f}, MAE: {mae_era5_land:.2f}, RMSE: {rmse_era5_land:.2f}, Bias: {bias_era5_land:.2f}\")\n",
    "            print(f\"Metrics VNP21A1D for {location['name']} - R^2: {r2_thermal:.2f}, MAE: {mae_thermal:.2f}, RMSE: {rmse_thermal:.2f}, Bias: {bias_thermal:.2f}\")\n",
    "            print(f\"Metrics MODIS for {location['name']} - R^2: {r2_modis:.2f}, MAE: {mae_modis:.2f}, RMSE: {rmse_modis:.2f}, Bias: {bias_modis:.2f}\")\n",
    "            L.append(location['name'])\n",
    "            R2_ERA5.append(r2_era5)\n",
    "            MAE_ERA5.append(mae_era5)\n",
    "            RMSE_ERA5.append(rmse_era5)\n",
    "            BIAS_ERA5.append(bias_era5)\n",
    "            R2_ERA5_LAND.append(r2_era5_land)\n",
    "            MAE_ERA5_LAND.append(mae_era5_land)\n",
    "            RMSE_ERA5_LAND.append(rmse_era5_land)\n",
    "            BIAS_ERA5_LAND.append(bias_era5_land)\n",
    "            R2_THERMAL.append(r2_thermal)\n",
    "            MAE_THERMAL.append(mae_thermal)\n",
    "            RMSE_THERMAL.append(rmse_thermal)\n",
    "            BIAS_THERMAL.append(bias_thermal)\n",
    "            R2_MODIS.append(r2_modis)\n",
    "            MAE_MODIS.append(mae_modis)\n",
    "            RMSE_MODIS.append(rmse_modis)\n",
    "            BIAS_MODIS.append(bias_modis)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error procesando el archivo para {location['name']}: {e}\")\n",
    "        # AquÃ­ puedes optar por realizar alguna acciÃ³n adicional, como registrar el error\n",
    "        continue  # Continuar con la siguiente iteraciÃ³n del bucle\n",
    "\n",
    "    # Si necesitas agregar mÃ¡s excepciones que puedan ocurrir, puedes agregarlas aquÃ­\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Archivo no encontrado para {location['name']}: {e}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Se produjo un error inesperado para {location['name']}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "# Set the positions of the points on the x-axis\n",
    "x = np.arange(len(L))\n",
    "\n",
    "# Define the metrics and corresponding data lists\n",
    "metrics = ['R2', 'MAE', 'RMSE', 'BIAS']\n",
    "data_ERA5 = [R2_ERA5, MAE_ERA5, RMSE_ERA5, BIAS_ERA5]\n",
    "data_ERA5_LAND = [R2_ERA5_LAND, MAE_ERA5_LAND, RMSE_ERA5_LAND, BIAS_ERA5_LAND]\n",
    "data_THERMAL=[R2_THERMAL, MAE_THERMAL, RMSE_THERMAL, BIAS_THERMAL]\n",
    "data_MODIS=[R2_MODIS, MAE_MODIS, RMSE_MODIS, BIAS_MODIS]\n",
    "\n",
    "# Iterate over metrics and create plots\n",
    "for metric, data_era5, data_era5_land, data_thermal, data_modis in zip(metrics, data_ERA5, data_ERA5_LAND,data_THERMAL, data_MODIS):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.scatter(x, data_era5, label='ERA5')\n",
    "    for i, location in enumerate(L):\n",
    "        plt.plot([i, i], [0, data_era5[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x, data_era5_land, label='ERA5-LAND')\n",
    "    for i, location in enumerate(L):\n",
    "        plt.plot([i, i], [0, data_era5_land[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x,data_thermal, label='VNP21A1D')\n",
    "    for i,location in enumerate(L):\n",
    "        plt.plot([i,i],[0,data_thermal[i]], color='black', linestyle='-')\n",
    "    plt.scatter(x,data_modis, label='MODIS')\n",
    "    for i,location in enumerate(L):\n",
    "        plt.plot([i,i],[0,data_modis[i]], color='black', linestyle='-')\n",
    "    plt.xlabel('Climate Stations')\n",
    "    plt.ylabel(metric)\n",
    "    if metric == 'R2':\n",
    "        plt.ylim(min(min(data_era5_land), min(data_era5),min(data_thermal),min(data_modis)) - 0.01, max(max(data_era5_land), max(data_era5),max(data_thermal),max(data_modis)) + 0.01)\n",
    "    else:\n",
    "        plt.ylim(min(min(data_era5_land), min(data_era5),min(data_thermal),min(data_modis)) - 0.1, max(max(data_era5_land), max(data_era5),max(data_thermal),max(data_modis)) + 0.1)\n",
    "    plt.axhline(y=0, color='black', linestyle='-')\n",
    "    plt.title(metric + ' ' + Parameter)\n",
    "    plt.xticks(x, L, rotation=90)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
